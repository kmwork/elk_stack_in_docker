version: '3.2'

services:
  elasticsearch:
    build:
      context: elasticsearch/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - type: bind
        source: ./elasticsearch/config/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
      - type: volume
        source: elasticsearch
        target: /usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"
      ELASTIC_PASSWORD: changeme
      # Use single node discovery in order to disable production mode and avoid bootstrap checks
      # see https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    networks:
      - elk
  zoo1:
    image: zookeeper:3.4.9
    hostname: zoo1
    ports:
      - "2181:2181"
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: 2181
      ZOO_SERVERS: server.1=zoo1:2888:3888
    volumes:
      - ./zk-single-kafka-single/zoo1/data:/data
      - ./zk-single-kafka-single/zoo1/datalog:/datalog

  kafka1:
    image: confluentinc/cp-kafka:5.5.1
    hostname: kafka1
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - ./zk-single-kafka-single/kafka1/data:/var/lib/kafka/data
    depends_on:
      - zoo1
#  zookeeper:
#    restart: always
#    image: wurstmeister/zookeeper
#    environment:
#      - ALLOW_ANONYMOUS_LOGIN=yes
#    expose:
#      - "2181"
#    networks:
#      - elk
#  kafka:
#    restart: always
#    image: wurstmeister/kafka
#    ports:
#      - "9092"
#    environment:
#      - KAFKA_ADVERTISED_HOST_NAME=172.29.40.67
#      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
#      - ALLOW_PLAINTEXT_LISTENER=yes
#      - KAFKA_MESSAGE_MAX_BYTES=20000000
#      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
#    volumes:
#      - 'kafka_data:/datana'
##  kafka:
##    restart: always
##    image: wurstmeister/kafka
##    depends_on:
##      - zookeeper
##    volumes:
##      - 'kafka_data:/datana'
##    ports:
##      - "9092:9094"
##    environment:
##      - KAFKA_ADVERTISED_HOST_NAME=172.29.40.67
##      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9094,OUTSIDE://localhost:9092
##      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9094,OUTSIDE://0.0.0.0:9092
##      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,OUTSIDE:PLAINTEXT
##      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
##      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
##      - ALLOW_PLAINTEXT_LISTENER=yes
##      - KAFKA_MESSAGE_MAX_BYTES=20000000
##      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
#    networks:
#      - elk
  logstash:
    restart: always
    build:
      context: logstash/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - type: bind
        source: ./logstash/config/logstash.yml
        target: /usr/share/logstash/config/logstash.yml
        read_only: true
      - type: bind
        source: ./logstash/pipeline
        target: /usr/share/logstash/pipeline
        read_only: true
    ports:
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    depends_on:
      - kafka
      - elasticsearch
    environment:
      BOOTSTRAP_SERVERS: "kafka1:19092"
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    networks:
      - elk
  kibana:
    image: kibana:$ELK_VERSION
    restart: always
    build:
      context: kibana/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - type: bind
        source: ./kibana/config/kibana.yml
        target: /usr/share/kibana/config/kibana.yml
        read_only: true
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - elk

networks:
  elk:
    driver: bridge

volumes:
  elasticsearch:
    driver: local
  zookeeper_data:
    driver: local
  kafka_data:
    driver: local

