version: '3.2'
## система логов в докерах
services:
  elasticsearch:
    image: elasticsearch:$ELK_VERSION
    build:
      context: elasticsearch/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - type: bind
        source: ./elasticsearch/config/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
      - type: volume
        source: elasticsearch
        target: /usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"
      ELASTIC_PASSWORD: changeme
      # Use single node discovery in order to disable production mode and avoid bootstrap checks
      # see https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    networks:
      - network_elk
  zoo1:
    restart: always
    image: wurstmeister/zookeeper
    expose:
      - "2181"
    volumes:
      - ./zk-single-kafka-single/zoo1/data:/data
      - ./zk-single-kafka-single/zoo1/datalog:/datalog
    networks:
      - network_kafka

  kafka1:
    image: wurstmeister/kafka
    hostname: kafka1
    ports:
      - "9092:9092"
    environment:
        KAFKA_ADVERTISED_LISTENERS: "LISTENER_DOCKER_INTERNAL://kafka1:19092, LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092"
        KAFKA_LISTENERS: "LISTENER_DOCKER_INTERNAL://0.0.0.0:19092, LISTENER_DOCKER_EXTERNAL://0.0.0.0:9092"
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "LISTENER_DOCKER_INTERNAL:PLAINTEXT, LISTENER_DOCKER_EXTERNAL:PLAINTEXT"
        KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
        KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
        KAFKA_BROKER_ID: 1
        KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
        KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
        KAFKA_CREATE_TOPICS: "datana_smart_logs:1:1"
        KAFKA_LISTENER_NAME: PLAINTEXT
        ALLOW_PLAINTEXT_LISTENER: "yes"
        KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    volumes:
      - ./zk-single-kafka-single/kafka1/data:/var/lib/kafka/data
    depends_on:
      - zoo1
    networks:
      - network_kafka
  logstash:
    image: logstash:$ELK_VERSION
    restart: always
    build:
      context: logstash/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - type: bind
        source: ./logstash/config/logstash.yml
        target: /usr/share/logstash/config/logstash.yml
        read_only: true
      - type: bind
        source: ./logstash/pipeline
        target: /usr/share/logstash/pipeline
        read_only: true
    ports:
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    depends_on:
      - kafka1
      - elasticsearch
    environment:
      BOOTSTRAP_SERVERS: "kafka1:19092"
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    networks:
      - network_elk
      - network_kafka
  kibana:
    image: kibana:$ELK_VERSION
    restart: always
    build:
      context: kibana/
      args:
        ELK_VERSION: $ELK_VERSION
    volumes:
      - type: bind
        source: ./kibana/config/kibana.yml
        target: /usr/share/kibana/config/kibana.yml
        read_only: true
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - network_elk

networks:
  network_elk:
    driver: bridge
  network_kafka:
    driver: bridge
volumes:
  elasticsearch:
    driver: local
  zookeeper_data:
    driver: local
  kafka_data:
    driver: local

